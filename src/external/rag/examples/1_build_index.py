"""
LargeRAG ç¤ºä¾‹ 1: æ„å»ºç´¢å¼•
====================================

åŠŸèƒ½å±•ç¤ºï¼š
1. åˆå§‹åŒ– LargeRAG
2. ä»æ–‡ä»¶å¤¹ç»“æ„åŠ è½½æ–‡çŒ®æ•°æ®
3. æ„å»ºå‘é‡ç´¢å¼•ï¼ˆå«ç¼“å­˜ã€æ‰¹å¤„ç†ï¼‰
4. æŸ¥çœ‹ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
5. å±•ç¤ºæ–‡æ¡£å¤„ç†ç»†èŠ‚ï¼ˆå…ƒæ•°æ®ã€åˆ†å—ï¼‰

è¿è¡Œæ–¹å¼ï¼š
    python examples/1_build_index.py
"""

import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from largerag import LargeRAG


def print_section(title: str):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70)


def main():
    print_section("LargeRAG ç´¢å¼•æ„å»ºç¤ºä¾‹")

    # ============================================================
    # 1. åˆå§‹åŒ– LargeRAG
    # ============================================================
    print_section("æ­¥éª¤ 1: åˆå§‹åŒ– LargeRAG")

    print("\nåˆå§‹åŒ–é…ç½®æ¥æº:")
    print("  - é…ç½®æ–‡ä»¶: config/settings.yaml")
    print("  - API Key: .env æ–‡ä»¶ä¸­çš„ DASHSCOPE_API_KEY")
    print("  - å‘é‡æ•°æ®åº“: Chroma (æŒä¹…åŒ–å­˜å‚¨)")
    print("  - ç¼“å­˜ç³»ç»Ÿ: æœ¬åœ°æ–‡ä»¶ç¼“å­˜ (å¯é€‰ Redis)")

    start_time = time.time()
    rag = LargeRAG()
    init_time = time.time() - start_time

    print(f"\nâœ“ åˆå§‹åŒ–å®Œæˆ (è€—æ—¶: {init_time:.2f}ç§’)")

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç´¢å¼•
    if rag.query_engine is not None:
        print("  âš ï¸  æ£€æµ‹åˆ°å·²æœ‰ç´¢å¼•ï¼Œæœ¬æ¬¡è¿è¡Œå°†è¦†ç›–æ—§ç´¢å¼•")
        existing_stats = rag.get_stats()
        print(f"  ç°æœ‰ç´¢å¼•èŠ‚ç‚¹æ•°: {existing_stats['index_stats'].get('document_count', 0)}")
    else:
        print("  â„¹ï¸  æœªæ£€æµ‹åˆ°å·²æœ‰ç´¢å¼•ï¼Œå°†ä»å¤´æ„å»º")

    # ============================================================
    # 2. æŒ‡å®šæ–‡çŒ®ç›®å½•
    # ============================================================
    print_section("æ­¥éª¤ 2: å‡†å¤‡æ–‡çŒ®æ•°æ®")

    literature_dir = str(Path(__file__).parent.parent / "data" / "test_5papers")

    print(f"\næ–‡çŒ®ç›®å½•: {literature_dir}")
    print("\næ–‡ä»¶å¤¹ç»“æ„è¯´æ˜:")
    print("  data/literature/")
    print("    â”œâ”€â”€ {hash1}/")
    print("    â”‚   â”œâ”€â”€ content_list_process.json  â† ä¼˜å…ˆä½¿ç”¨")
    print("    â”‚   â”œâ”€â”€ article.json               â† å¤‡é€‰")
    print("    â”‚   â”œâ”€â”€ {hash1}.md                 (ä¸ä½¿ç”¨)")
    print("    â”‚   â””â”€â”€ images/                    (ä¸å¤„ç†)")
    print("    â””â”€â”€ {hash2}/")
    print("        â””â”€â”€ ...")

    # ç»Ÿè®¡æ–‡çŒ®æ•°é‡
    lit_path = Path(literature_dir)
    if lit_path.exists():
        folder_count = len([d for d in lit_path.iterdir() if d.is_dir()])
        print(f"\nâœ“ æ£€æµ‹åˆ° {folder_count} ä¸ªæ–‡çŒ®æ–‡ä»¶å¤¹")
    else:
        print(f"\nâœ— é”™è¯¯: æ–‡çŒ®ç›®å½•ä¸å­˜åœ¨: {literature_dir}")
        return False

    # ============================================================
    # 3. æ„å»ºç´¢å¼•ï¼ˆå…³é”®æ­¥éª¤ï¼‰
    # ============================================================
    print_section("æ­¥éª¤ 3: æ„å»ºå‘é‡ç´¢å¼•")

    print("\nç´¢å¼•æ„å»ºæµç¨‹:")
    print("  [1] æ–‡æ¡£åŠ è½½      - ä» JSON æå–æ–‡æœ¬æ®µè½")
    print("  [2] æ–‡æ¡£åˆ†å—      - SentenceSplitter (chunk_size=512, overlap=50)")
    print("  [3] Embedding     - DashScope text-embedding-v3 (1024ç»´)")
    print("  [4] ç¼“å­˜æ£€æŸ¥      - è·³è¿‡å·²è®¡ç®—çš„ embedding (èŠ‚çœAPIè°ƒç”¨)")
    print("  [5] å‘é‡å­˜å‚¨      - æŒä¹…åŒ–åˆ° Chroma æ•°æ®åº“")

    print("\nå¼€å§‹æ„å»ºç´¢å¼•...\n")

    start_time = time.time()
    success = rag.index_from_folders(literature_dir)
    index_time = time.time() - start_time

    if not success:
        print("\nâœ— ç´¢å¼•æ„å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
        return False

    print(f"\nâœ“ ç´¢å¼•æ„å»ºæˆåŠŸ (æ€»è€—æ—¶: {index_time:.2f}ç§’ / {index_time/60:.2f}åˆ†é’Ÿ)")

    # æ€§èƒ½å‚è€ƒ
    print("\næ€§èƒ½å‚è€ƒ:")
    print(f"  - å®é™…è€—æ—¶: {index_time:.2f}ç§’")
    print(f"  - æ€§èƒ½ç›®æ ‡: <180ç§’ (3åˆ†é’Ÿ) for 35ç¯‡æ–‡çŒ®")
    if index_time < 180:
        print(f"  âœ… æ€§èƒ½è¾¾æ ‡ï¼")
    else:
        print(f"  âš ï¸  è¶…å‡ºç›®æ ‡ {index_time-180:.1f}ç§’")

    # ============================================================
    # 4. æŸ¥çœ‹ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
    # ============================================================
    print_section("æ­¥éª¤ 4: ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯")

    stats = rag.get_stats()

    # 4.1 ç´¢å¼•ç»Ÿè®¡
    print("\nğŸ“Š å‘é‡ç´¢å¼•ç»Ÿè®¡:")
    index_stats = stats['index_stats']
    print(f"  Collection åç§°: {index_stats.get('collection_name', 'N/A')}")
    print(f"  ç´¢å¼•èŠ‚ç‚¹æ•°:      {index_stats.get('document_count', 0)}")
    print(f"  å­˜å‚¨ä½ç½®:        {index_stats.get('persist_directory', 'N/A')}")

    print("\n  è¯´æ˜:")
    print("  - èŠ‚ç‚¹æ•° = æ–‡æ¡£åˆ†å—åçš„ç‰‡æ®µæ•°é‡")
    print("  - æ¯ä¸ªèŠ‚ç‚¹åŒ…å« ~512 tokens çš„æ–‡æœ¬ + 1024ç»´å‘é‡")

    # 4.2 æ–‡æ¡£å¤„ç†ç»Ÿè®¡
    print("\nğŸ“Š æ–‡æ¡£å¤„ç†ç»Ÿè®¡:")
    doc_stats = stats['doc_processing_stats']
    processed = doc_stats.get('processed', 0)
    skipped = doc_stats.get('skipped', 0)
    total = doc_stats.get('total', 0)

    print(f"  å·²å¤„ç†æ–‡æ¡£æ®µè½: {processed}")
    print(f"  è·³è¿‡æ–‡æ¡£:        {skipped}")
    print(f"  æ€»è®¡:            {total}")

    if total > 0:
        success_rate = (processed / total) * 100
        print(f"  æˆåŠŸç‡:          {success_rate:.2f}%")

        if success_rate >= 95:
            print(f"  âœ… æˆåŠŸç‡è¾¾æ ‡ (ç›®æ ‡: >95%)")
        else:
            print(f"  âš ï¸  æˆåŠŸç‡ä¸è¶³ {95-success_rate:.1f}%")

    print("\n  è¯´æ˜:")
    print("  - æ®µè½æ•° â‰  èŠ‚ç‚¹æ•°ï¼ˆå› ä¸ºä¼šè¿›ä¸€æ­¥åˆ†å—ï¼‰")
    print("  - è·³è¿‡çš„æ–‡æ¡£å¯èƒ½æ˜¯ç©ºæ–‡æœ¬æˆ–æ ¼å¼é”™è¯¯")

    # ============================================================
    # 5. å±•ç¤ºæ–‡æ¡£å¤„ç†ç»†èŠ‚
    # ============================================================
    print_section("æ­¥éª¤ 5: æ–‡æ¡£å¤„ç†ç»†èŠ‚å±•ç¤º")

    print("\nä»ç´¢å¼•ä¸­é‡‡æ · 3 ä¸ªèŠ‚ç‚¹ï¼Œå±•ç¤ºå…ƒæ•°æ®å’Œå†…å®¹:")

    # ä½¿ç”¨ä¸€ä¸ªç®€å•æŸ¥è¯¢æ¥è·å–ä¸€äº›èŠ‚ç‚¹
    sample_docs = rag.get_similar_docs("deep eutectic solvents", top_k=3)

    for i, doc in enumerate(sample_docs, 1):
        print(f"\n--- èŠ‚ç‚¹ {i} ---")
        print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {doc['score']:.4f}")

        metadata = doc['metadata']
        print(f"\nå…ƒæ•°æ®:")
        print(f"  æ–‡æ¡£å“ˆå¸Œ:   {metadata.get('doc_hash', 'N/A')[:16]}...")
        print(f"  æ¥æºæ–‡ä»¶:   {metadata.get('source_file', 'N/A')}")
        print(f"  é¡µç :       {metadata.get('page_idx', 'N/A')}")
        print(f"  æ–‡æœ¬å±‚çº§:   {metadata.get('text_level', 'N/A')}")
        print(f"  å«å¼•ç”¨:     {metadata.get('has_citations', 'N/A')}")

        text = doc['text']
        print(f"\næ–‡æœ¬å†…å®¹ (å‰200å­—ç¬¦):")
        print(f"  {text[:200]}...")
        print(f"  [æ€»é•¿åº¦: {len(text)} å­—ç¬¦]")

    # ============================================================
    # 6. ç¼“å­˜ç³»ç»Ÿè¯´æ˜
    # ============================================================
    print_section("æ­¥éª¤ 6: ç¼“å­˜ç³»ç»Ÿè¯´æ˜")

    print("\nç¼“å­˜æœºåˆ¶:")
    print("  âœ“ æœ¬åœ°æ–‡ä»¶ç¼“å­˜å·²å¯ç”¨ (config/settings.yaml: cache.enabled=true)")
    print("  âœ“ ç¼“å­˜ç±»å‹: æœ¬åœ°æ–‡ä»¶ (type=local)")
    print("  âœ“ ç¼“å­˜ä½ç½®: src/tools/largerag/data/cache/")

    print("\nç¼“å­˜å·¥ä½œåŸç†:")
    print("  1. é¦–æ¬¡ç´¢å¼•: è®¡ç®— embedding å¹¶ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ (pickle æ ¼å¼)")
    print("  2. é‡å¤ç´¢å¼•: æ£€æŸ¥ç¼“å­˜ï¼Œå¦‚æœå­˜åœ¨ç›´æ¥è¯»å–ï¼Œå¦åˆ™è°ƒç”¨ API")
    print("  3. ç¼“å­˜é”®:   åŸºäºæ–‡æ¡£å†…å®¹çš„å“ˆå¸Œï¼Œç¡®ä¿å”¯ä¸€æ€§")

    print("\nç¼“å­˜ä¼˜åŠ¿:")
    print("  âœ“ é¿å…é‡å¤è°ƒç”¨ DashScope API (èŠ‚çœæˆæœ¬)")
    print("  âœ“ åŠ é€Ÿé‡å¤ç´¢å¼• (100å€+ é€Ÿåº¦æå‡)")
    print("  âœ“ æ”¯æŒå¢é‡ç´¢å¼• (æ–°å¢æ–‡çŒ®æ—¶è€æ–‡çŒ®ç”¨ç¼“å­˜)")

    print("\næç¤º:")
    print("  - å†æ¬¡è¿è¡Œæœ¬è„šæœ¬å°†ä½¿ç”¨ç¼“å­˜ï¼Œé€Ÿåº¦ä¼šå¤§å¹…æå‡")
    print("  - å¦‚éœ€æ¸…ç©ºç¼“å­˜: rm -rf src/tools/largerag/data/cache")

    # ============================================================
    # 7. ä¸‹ä¸€æ­¥æ“ä½œ
    # ============================================================
    print_section("å®Œæˆï¼")

    print("\nâœ… ç´¢å¼•æ„å»ºå®Œæˆï¼Œç°åœ¨å¯ä»¥:")
    print("  1. è¿è¡ŒæŸ¥è¯¢ç¤ºä¾‹: python examples/2_query_and_retrieve.py")
    print("  2. åœ¨ä»£ç ä¸­ä½¿ç”¨:")
    print("      from largerag import LargeRAG")
    print("      rag = LargeRAG()  # è‡ªåŠ¨åŠ è½½å·²æœ‰ç´¢å¼•")
    print("      answer = rag.query('ä½ çš„é—®é¢˜')")

    print("\nç´¢å¼•æ–‡ä»¶ä½ç½®:")
    print(f"  {index_stats.get('persist_directory', 'N/A')}")
    print("  (Chroma æ•°æ®åº“ä¼šè‡ªåŠ¨æŒä¹…åŒ–ï¼Œé‡å¯åè‡ªåŠ¨åŠ è½½)")

    print("\n" + "=" * 70 + "\n")

    return True


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
